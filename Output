# Model-based algorithms

## Policy iteration
Policy static after 1 iterations
[['v' '>' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' 'v' 'v' '^']
 ['^' '>' '>' '^']]
[[0.45 0.5  0.58 0.5 ]
 [0.51 0.   0.65 0.  ]
 [0.58 0.67 0.77 0.  ]
 [0.   0.77 0.89 1.  ]]

## Value iteration
[['v' '>' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' 'v' 'v' '^']
 ['^' '>' '>' '^']]
[[0.45 0.5  0.58 0.5 ]
 [0.51 0.   0.65 0.  ]
 [0.58 0.67 0.77 0.  ]
 [0.   0.77 0.89 1.  ]]

# Model-free algorithms

##_Sarsa
Number of Episodes: 2500
Incorrect Policies: 4
[['<' '^' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' 'v' '^' '^']
 ['^' '>' '>' 'v']]
[[0.05 0.05 0.21 0.13]
 [0.1  0.   0.34 0.  ]
 [0.13 0.58 0.37 0.  ]
 [0.   0.79 0.9  1.  ]]
Number of episodes 2856
[['v' '>' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' 'v' 'v' '^']
 ['^' '>' '>' '^']]
[[0.03 0.1  0.12 0.11]
 [0.05 0.   0.42 0.  ]
 [0.09 0.32 0.65 0.  ]
 [0.   0.66 0.9  1.  ]]

##_Q-learning
Number of Episodes: 2500
Incorrect Policies: 1
[['v' '>' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' 'v' 'v' '^']
 ['^' '>' '>' 'v']]
[[0.47 0.42 0.48 0.46]
 [0.53 0.   0.56 0.  ]
 [0.6  0.68 0.72 0.  ]
 [0.   0.75 0.89 1.  ]]
Number of episodes: 3274
[['v' '>' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' 'v' 'v' '^']
 ['^' '>' '>' '^']]
[[0.45 0.5  0.51 0.46]
 [0.51 0.   0.53 0.  ]
 [0.56 0.57 0.61 0.  ]
 [0.   0.67 0.88 1.  ]]

## Linear Sarsa
[['>' '>' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' 'v' 'v' '^']
 ['^' '>' '>' '^']]
[[0.42 0.48 0.57 0.42]
 [0.44 0.   0.66 0.  ]
 [0.51 0.63 0.78 0.  ]
 [0.   0.77 0.89 1.  ]]

## Linear Q-learning
[['>' '>' 'v' '<']
 ['v' '^' 'v' '^']
 ['>' '>' 'v' '^']
 ['^' '>' '>' '^']]
[[0.44 0.5  0.59 0.5 ]
 [0.45 0.   0.67 0.  ]
 [0.57 0.64 0.78 0.  ]
 [0.   0.77 0.89 1.  ]]